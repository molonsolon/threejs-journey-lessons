# Common Textures

## Color (or Albedo)
* most simple
* applied to geometry 
![](https://threejs-journey.com/assets/lessons/11/000.jpg)

## Alpha
* grayscale image
* white visible
* black no visible
![](https://threejs-journey.com/assets/lessons/11/001.jpg)

## Height (or Displacement)
* greyscale 
* move the vertices to create some relief
* need enough subdivision
![](https://threejs-journey.com/assets/lessons/11/002.png)

## Normal
* adds detaiil
* doesn't need subdivision
* vertices won't move
* lure the light about the face orientation
* better performance than adding a height texture with a lot of subdivision
![](https://threejs-journey.com/assets/lessons/11/003.jpg)

## Ambient Occlusion
* grayscale image
* add fake shadows in crevices
* not physically accurate
* helps to create contrast and see details
![](https://threejs-journey.com/assets/lessons/11/004.jpg)

## Metalness
* grayscale image
* white is metallic
* black is non-metallic
* mostly for reflection
![](https://threejs-journey.com/assets/lessons/11/005.jpg)

## Roughness
* grayscale image
* often in combo with metalness
* white is rough
* black is smooth
* mostly for light dissipation
![](https://threejs-journey.com/assets/lessons/11/006.jpg)

## PBR
These textures (esp metalness and roughness) follow PBR principles

* Physically based rendering
* many techniques that tend to follow real-life directions to get realistic results
* becoming standard for realistic renders
* many software, engines, and libraries are using it

for more info: 
*  https://marmoset.co/posts/basic-theory-of-physically-based-rendering/
* https://marmoset.co/posts/
physically-based-rendering-and-you-can-too/

# How to load textures

## Getting URL of the image
To load texture, we need URL of the image file. With webpack, there are two ways of doing this

1. Put the image texture in the `/src/` folder and import

2. Put the image in the `/static/` folder and access it directly. This is the technique we will use

## Loading the image
There are multiple ways to load an image

### Using native JavaScript
Create an `Image` instance, listen to the `load` event, and change its `src`.

Create a `texture` variable with the Texture class
We need to use that `texture` in the `material`.
Unfortunately, the `texture` variable cannot be accessed directly because it's inside our `onload(...)` function.

### Using TextureLoader
Instantiate a variable using the `TextureLoader` class and use its `.load(...)` method to create a new texture

One instance of `TextureLoader` can load as many textures as needed.

Can send 3 functions after the path URL:
* `load` - when the image loaded successfully
* `progress` - shows progress
* `error` - displays error if image cannot be loaded 

### Using LoadingManager
The purpose is to mutualize the events. It's useful if we want to know the global loading progress or be informed when everything is loaded.

## UV Unwrapping
Texture is being stretched or squeezed in different ways to cover the geometry
this is UV unwrapping, each vertex will have 2D coordinates on a flat plane. Sort of like origami!

We can see these UV coordinates in `geometry.attributes.uv`. These are generated by Three.js. If you create your own you'll have to specify UV coordinates. If you're using 3D software, you'll also have to specify UV unwrapping.

## Transforming textures

### Repeat

We can use the `repeat` property to repeat the texture. Uses a Vector2 with `x` and `y` properties. we change `THREE.RepeatWrapping` on the `wrapS` and `wrapT` props. we can alternate direction with `THREE.MirroredRepeatWrapping`

we can offset the texture using the `offset` property (Vector2)

### Rotate
use the `rotation` property to rotate the texture. To rotate half a revolution, use `Math.PI`, multiply by 2 for full rev. 

Rotation occurs around the bottom left corner by default. this is the `0, 0` UV coordinate. Move the pivot point with the `center` property (Vector2).

### Filtering and Mipmapping
If you look at top face while face is almost hidden, you'll see a blurry texture. This is due to filtering and mipmapping.

Mipmapping is a technique that consists of creating half of a texture again and again until we get a 1x1 texture. GPU will use different versions depending on how much of the pixel you can see. This is handled by Three.js but we can use different algorithms.

#### Minification filter
happens when pixels of of texture are smaller than pixels of render. Texture is too big for surface it covers. can change using the `minFilter` property with 6 differenet values. 

* `Three.NearestFilter` (very sharp)
* `Three.LinearFilter`
* `Three.NearestMipmapNearestFilter`
* `Three.NearestMipmapLinearFilter`
* `Three.LinearMipmapNearestFilter`
* `Three.LinearMipmapLinearFilter` (default)

Artifacts seen when zoomed out are called mo√≠re patterns (test with checkerboard-1024)

If you're using `THREE.NearestFilter` on `minFilter` we don't need mipmaps and can deactivate with `colorTexture.generateMipmaps = fale`

#### Magnification filter
Happens when pixels of texture are bigger than pixels of render. Texture is too small for the surface it covers. It looks bad but it depends on the context. If the effect isn't too exaggerateed, the user will probably not notice. 

We can change the magnification filiter using the `magFilter` prop with these 2 values.
* `Three.NearestFilter` - scales texture to remove blur (minecraft style)
* `Three.LinearFilter` (default, better performance)

## Texture format and optimization
When preparing textures keep 3 things in mind. The difficulty is finding the right combination of texture formats and resolutions.
* The weight
* The size (resolution)
* The data

### Weight
Users will have to download textures, so choose right type of file
* `.jpg` - lossy compression but usually lighter
* `.png` - lossless compression but usually heavier
Use compression websites/software like TinyPNG if needed

### Size
Each pixel of texture will be stored on GPU regardless of image's weight
GPU has storage limitation, even worse because mipmapping increases pixels stored. try to reduce size of image as much as possible. 

mipmapping will produce half texture repeatedly until 1x1. Because of that, texture width and height must be a power of 2. 

### Data
Textures support transparency but we can't have transparency in `.jpg` If we want to have only one texture that combines color and alpha, we need to use `.png` file. 

If using a `normal` texture we want to have the exact values which is why we shouldn't apply lossy compression and should stick to `.png`

Sometimes we can combine different data into one texture using red, green, blue and alpha channels seperately. 

## Where to find textures
Always hard to find textures, but a couple good places to start.
* poliigon.com
* 3dtextures.me
* arroway-textures.ch

Can also create you own using photos and 2D software like Photoshop or even procedural textures with software like https://www.substance3d.com/products/substance-designer/